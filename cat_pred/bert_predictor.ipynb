{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from JSON file\n",
    "with open('./EventData.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "# Create pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "def extract_start_end_hour(time_str):\n",
    "    if time_str:\n",
    "        time_components = time_str.split('-')\n",
    "        if len(time_components) >= 2:\n",
    "            start_time_parts = time_components[0].split(':') if ':' in time_components[0] else time_components[0].split('.')\n",
    "            start_hour = int(start_time_parts[0]) if start_time_parts[0].isdigit() else 0\n",
    "            start_minute = int(start_time_parts[1]) if len(start_time_parts) > 1 and start_time_parts[1].isdigit() else 0\n",
    "            \n",
    "            end_time_parts = time_components[-1].split(':') if ':' in time_components[-1] else time_components[-1].split('.')\n",
    "            end_hour = int(end_time_parts[0]) if end_time_parts[0].isdigit() else 0\n",
    "            end_minute = int(end_time_parts[1]) if len(end_time_parts) > 1 and end_time_parts[1].isdigit() else 0\n",
    "            \n",
    "            return start_hour, start_minute, end_hour, end_minute\n",
    "    return 0, 0, 0, 0\n",
    "\n",
    "df['start_hour'], df['start_minute'], df['end_hour'], df['end_minute'] = zip(*df['time'].apply(extract_start_end_hour))\n",
    "df['duration'] = (df['end_hour'] * 60 + df['end_minute']) - (df['start_hour'] * 60 + df['start_minute'])\n",
    "df['title'] = df['title'].fillna('')\n",
    "df['description'] = df['description'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['title', 'start_hour', 'start_minute', 'end_hour', 'end_minute', 'duration', 'nation', 'description']\n",
    "target = 'category'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(), 'title'),\n",
    "        ('text_desc', TfidfVectorizer(), 'description'),\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['nation']),\n",
    "        ('numeric', SimpleImputer(strategy='mean'), ['start_hour', 'start_minute', 'end_hour', 'end_minute', 'duration'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(len(X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict categories for new data\n",
    "new_data = {\n",
    "    \"title\": [\"Live wmusic - Tomas Rimeika & Anton \\u00c5nell - at Gotlands' Pub!\"],\n",
    "    \"start_hour\": [18],\n",
    "    \"start_minute\": [0],\n",
    "    \"end_hour\": [2],\n",
    "    \"end_minute\": [0],\n",
    "    \"duration\": [1000],\n",
    "    \"nation\": [\"Gotlands nation\"],\n",
    "    \"description\": [\"\"]\n",
    "}\n",
    "predicted_categories = model.predict(pd.DataFrame(new_data))\n",
    "print(\"Predicted categories for new data:\", predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./events.json', 'r') as f:\n",
    "    live_events_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame from the loaded data\n",
    "live_events_df = pd.DataFrame(live_events_data)\n",
    "\n",
    "# Feature engineering\n",
    "live_events_df['date'] = pd.to_datetime(live_events_df['date'])\n",
    "live_events_df['start_hour'] = live_events_df['time'].apply(extract_start_hour)\n",
    "\n",
    "\n",
    "def extract_start_hour(time_str):\n",
    "    if time_str:\n",
    "        return int(time_str.split(':')[0])\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_events_df['start_hour'] = live_events_df['time'].apply(extract_start_hour)\n",
    "# Define features to be used for prediction\n",
    "live_features = ['title', 'start_hour']\n",
    "\n",
    "# Define preprocessing pipeline for live events\n",
    "live_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(), 'title'),\n",
    "        ('numeric', SimpleImputer(strategy='mean'), ['start_hour'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Preprocess live event data\n",
    "preprocessed_live_events = live_preprocessor.fit_transform(live_events_df[live_features])\n",
    "print(preprocessed_live_events)\n",
    "# Load the trained model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Assuming you have preprocessor defined previously\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict categories for live events\n",
    "predicted_categories = model.predict(preprocessed_live_events)\n",
    "\n",
    "# Add predicted categories to the DataFrame\n",
    "live_events_df['predicted_category'] = predicted_categories\n",
    "\n",
    "# Display the DataFrame with predicted categories\n",
    "print(live_events_df[['title', 'predicted_category']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
